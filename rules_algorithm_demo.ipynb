{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification rules algorithm\n",
    "\n",
    "## 1. Designing the PRISM algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need datastructures to store the rules. The Rule consists of antecedent (Left Hand Side) and consequent (Right Hand Side).  The LHS includes multiple conditions joined with and, and RHS is a class label. The Rule also needs to store its accuracy and coverage.\n",
    "\n",
    "The list of conditions contains several objects of class Condition. Each condition includes the column name and the value. If the value is numeric, then the condition also includes an additional field `true_false` and is expressed in form: *if col >= val then True* or *if col >= val then False*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Rule:\n",
    "    def __init__(self, class_label):\n",
    "        self.conditions = []  # list of conditions\n",
    "        self.class_label = class_label  # rule class\n",
    "\n",
    "    def add_condition(self, condition):\n",
    "        self.conditions.append(condition)\n",
    "\n",
    "    def set_params(self, accuracy, coverage):\n",
    "        self.accuracy = accuracy\n",
    "        self.coverage = coverage\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"If {} then {}. Coverage:{}, accuracy: {}\".format(self.conditions, self.class_label,\n",
    "                                                                 self.coverage, self.accuracy)\n",
    "\n",
    "\n",
    "class Condition:\n",
    "    def __init__(self, attribute, value, true_false = None):\n",
    "        self.attribute = attribute\n",
    "        self.value = value\n",
    "        self.true_false = true_false\n",
    "\n",
    "    def __repr__(self):\n",
    "        if self.true_false is None:\n",
    "            return \"{}={}\".format(self.attribute, self.value)\n",
    "        else:\n",
    "            return \"{}>={}:{}\".format(self.attribute, self.value, self.true_false)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next comes the `learn_one_rule` algorithm. The required parameters are the names of the columns, the current subset of data, and the class label. The optional parameters are thresholds `min_coverage` and `min_accuracy`. Inaddition, sometimes we pass an already existing Rule in order to learn more refined condition. Now, if the Rule can be improved, we will return the new rule and the subset of data covered by the Rule. If we could not improve it - we return the original Rule and the original covered subset (`prev_covered`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learn_one_rule(columns, data, class_label, \n",
    "                   prev_rule=None, min_coverage=30,\n",
    "                   min_accuracy=0.6, prev_covered=None):\n",
    "    current_subset = data.copy()\n",
    "\n",
    "    current_rule = prev_rule\n",
    "    current_accuracy = 0\n",
    "    current_coverage = None\n",
    "    covered_subset = None\n",
    "    if current_rule is not None:\n",
    "        current_accuracy = current_rule.accuracy\n",
    "        current_coverage = current_rule.coverage\n",
    "        covered_subset = prev_covered.copy()\n",
    "    best_col = None\n",
    "    best_val = None\n",
    "    true_false = None\n",
    "\n",
    "    for col in columns[:-1]:\n",
    "        # Extract unique values from the column\n",
    "        unique_vals = current_subset[col].unique().tolist()\n",
    "        \n",
    "        # Consider each unique value in turn\n",
    "        for val in unique_vals:\n",
    "            \n",
    "            # The treatment is different for numeric and categorical attributes\n",
    "            if isinstance(val, int) or isinstance(val, float):\n",
    "                # Here we construct 2 conditions: \n",
    "                # if actual value >= val and if actual value < val\n",
    "                acc = [None]*2\n",
    "                cov = [None]*2\n",
    "                total_get = len(current_subset[current_subset[col] >= val])\n",
    "                correct_get = len(current_subset.loc[(current_subset[col] >= val)\n",
    "                                                 & (current_subset[columns[-1]] == class_label),])\n",
    "                total_lt = len(current_subset) - total_get\n",
    "                correct_lt = len(current_subset.loc[(current_subset[columns[-1]] == class_label),]) \\\n",
    "                             - correct_get\n",
    "                if total_get >= min_coverage:\n",
    "                    acc[0] = correct_get / total_get\n",
    "                    cov[0] = total_get\n",
    "                if total_lt >= min_coverage:\n",
    "                    acc[1] = correct_lt/total_lt\n",
    "                    cov[1] = total_lt\n",
    "\n",
    "                # we select the best out of the 2\n",
    "                best_i = None\n",
    "                if acc[0] is not None and (acc[1] is None or acc[0] > acc[1]):\n",
    "                    best_i = 0\n",
    "                elif acc[1] is not None and (acc[0] is None or acc[1] > acc[0]):\n",
    "                    best_i = 1\n",
    "                elif acc[0] is not None and acc[1] is not None and acc[0] == acc[1]:\n",
    "                    if total_get > total_lt:\n",
    "                        best_i = 0\n",
    "                    else:\n",
    "                        best_i = 1\n",
    "                \n",
    "                # Now we see if the best of the 2 is better than the previous accuracy\n",
    "                if best_i is not None:\n",
    "                    if acc[best_i] > current_accuracy or \\\n",
    "                            (acc[best_i] == current_accuracy and cov[best_i] > current_coverage):\n",
    "                        current_accuracy = acc[best_i]\n",
    "                        current_coverage = cov[best_i]\n",
    "\n",
    "                        best_col = col\n",
    "                        best_val = val\n",
    "                        true_false = bool(1 - best_i)\n",
    "            else:\n",
    "                # For categorical attributes - this is just single condition if actual value == val\n",
    "                total = len(current_subset[current_subset[col] == val])\n",
    "                if total < min_coverage:\n",
    "                    continue\n",
    "                correct = len(current_subset.loc[(current_subset[col] == val)\n",
    "                                                 & (current_subset[columns[-1]] == class_label),])\n",
    "\n",
    "                accuracy = correct / total\n",
    "\n",
    "                if accuracy > current_accuracy:\n",
    "                    current_accuracy = accuracy\n",
    "                    current_coverage = total\n",
    "                    best_col = col\n",
    "                    best_val = val\n",
    "                    true_false = None\n",
    "                elif accuracy == current_accuracy:\n",
    "                    if current_coverage is None or total > current_coverage:\n",
    "                        current_accuracy = accuracy\n",
    "                        current_coverage = total\n",
    "                        best_col = col\n",
    "                        best_val = val\n",
    "                        true_false = None\n",
    "\n",
    "            # print(best_col, best_val, current_accuracy, current_coverage)\n",
    "\n",
    "    # If we managed to improve the rule accuracy\n",
    "    if best_col is not None:\n",
    "        # If the rule does not exist - create it\n",
    "        if current_rule is None:\n",
    "            current_rule = Rule(class_label)\n",
    "        # Create a condition based on best_col, best_val and true_false\n",
    "        condition = Condition(best_col, best_val, true_false)\n",
    "        current_rule.add_condition(condition)\n",
    "        current_rule.set_params(current_accuracy, current_coverage)\n",
    "        \n",
    "        # Generate a subset covered by this rule\n",
    "        if true_false is None:\n",
    "            covered_subset = current_subset[current_subset[best_col] == best_val]\n",
    "        else:\n",
    "            if true_false == True:\n",
    "                covered_subset = current_subset[current_subset[best_col] >= best_val]\n",
    "            else:\n",
    "                covered_subset = current_subset[current_subset[best_col] < best_val]\n",
    "    \n",
    "    # If we did not refine the rule - return original rule and the original covered set\n",
    "    return (current_rule, covered_subset, best_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main algorithm `learn_rules` takes as parameters list of columns, with the last column representing the class label, and the original data in form of pandas dataframe. Optionally, you can pass the list of classes in order that you are interested to explore first. Two optional threshold parameters `min_coverage` and `min_accuracy` set up the conditions of rule's validity  for a specific dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def learn_rules (columns, data, classes=None, \n",
    "                 min_coverage = 30, min_accuracy = 0.6):\n",
    "    # List of final rules\n",
    "    rules = []\n",
    "    \n",
    "    # If list of classes of interest is not provided - it is extracted from the last column of data\n",
    "    if classes is not None:\n",
    "        class_labels = classes\n",
    "    else:\n",
    "        class_labels = data[columns[-1]].unique().tolist()\n",
    "\n",
    "    current_data = data.copy()\n",
    "    \n",
    "    # This follows the logic of the original PRISm algorithm\n",
    "    # It processes each class in turn. Because for high accuracy \n",
    "    # the rules generated are disjoint with respect to class label\n",
    "    # this is not a problem when we are just interested in rules themselves - not classification\n",
    "    # For classification the order in which the rules are discovered matters, and we should \n",
    "    # process all classes at the same time\n",
    "    for class_label in class_labels:\n",
    "        done = False\n",
    "        while len(current_data) > min_coverage and not done:\n",
    "            # Learn a rule with a single condition\n",
    "            rule, covered, new_col = learn_one_rule(columns, current_data, class_label,\n",
    "                                                    None, min_coverage, min_accuracy, None)\n",
    "            # The best rule does not pass the coverage threshold - we are done with this class\n",
    "            if rule is None:\n",
    "                break\n",
    "\n",
    "            # If we get the rule with coverage above threshold\n",
    "            # We try to refine this rule\n",
    "            if rule is not None:\n",
    "                 # try to improve the rule\n",
    "                while (new_col is not None and \\\n",
    "                       rule.accuracy < 1.0 and rule.coverage > min_coverage):   \n",
    "                    # keep the previously covered in case we were unable to improve in this iteration\n",
    "                    prev_covered = covered.copy()\n",
    "                    \n",
    "                    # remove the column already included in the rule condition\n",
    "                    subset = covered.drop(columns=[new_col])\n",
    "                    column_list = subset.columns.to_numpy().tolist()\n",
    "                    rule, covered, new_col = learn_one_rule(column_list, subset, class_label,\n",
    "                                                            rule, min_coverage, min_accuracy, \n",
    "                                                            prev_covered)\n",
    "\n",
    "                # done with this rule\n",
    "                if rule.accuracy >= min_accuracy:\n",
    "                    rules.append(rule)\n",
    "\n",
    "                    # remove rows covered by this rule\n",
    "                    # you have to remove the rows where all of the conditions hold\n",
    "                    # this is the only inefficient part of the implementation\n",
    "                    # because I was forced to loop over data frame and look at all the involved columns\n",
    "                    remaining_rows_index = []\n",
    "                    for ind in current_data.index:\n",
    "                        not_covered = False\n",
    "                        conditions = rule.conditions\n",
    "                        for cond in conditions:\n",
    "                            if cond.true_false is None:\n",
    "                                if current_data[cond.attribute][ind] != cond.value:\n",
    "                                    not_covered = True\n",
    "                                    break\n",
    "                            elif cond.true_false == True:\n",
    "                                if current_data[cond.attribute][ind] < cond.value:\n",
    "                                    not_covered = True\n",
    "                                    break\n",
    "                            else:\n",
    "                                if current_data[cond.attribute][ind] >= cond.value:\n",
    "                                    not_covered = True\n",
    "                                    break\n",
    "                        if not_covered:\n",
    "                            remaining_rows_index.append(ind)\n",
    "                            \n",
    "                    # These are the records after removing what was covered by the rule\n",
    "                    current_data = current_data.loc[remaining_rows_index,]\n",
    "                else:\n",
    "                    done = True\n",
    "            else:\n",
    "                done = True\n",
    "                \n",
    "    return rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. The rules of survival. Titanic dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Titanic [dataset](https://drive.google.com/file/d/1yLR3Mieai6k4lFAPoMFD6AK7ImrJ1A93/view?usp=sharing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = \"../../data_ml_2020/titanic.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows 714\n",
      "Columns: ['Pclass', 'Sex', 'Age', 'Survived']\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(data_file)\n",
    "\n",
    "data = data[['Pclass', 'Sex', 'Age', 'Survived']]\n",
    "\n",
    "data = data.dropna(how=\"any\")\n",
    "print(\"Total rows\", len(data))\n",
    "\n",
    "column_list = data.columns.to_numpy().tolist()\n",
    "print(\"Columns:\", column_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If [Sex=female, Pclass>=2:False, Age>=26.0:True] then 1. Coverage:57, accuracy: 0.9824561403508771\n",
      "If [Age>=6.0:False, Pclass>=2:True] then 1. Coverage:41, accuracy: 0.7073170731707317\n",
      "If [Sex=female, Pclass>=3:False, Age>=24.0:False] then 1. Coverage:37, accuracy: 0.972972972972973\n",
      "If [Sex=female, Pclass>=3:False, Age>=28.0:True] then 1. Coverage:41, accuracy: 0.926829268292683\n",
      "If [Age>=54.0:True, Sex=male] then 0. Coverage:37, accuracy: 0.8918918918918919\n",
      "If [Age>=39.0:True, Pclass>=2:True] then 0. Coverage:60, accuracy: 0.9166666666666666\n",
      "If [Sex=male, Pclass>=2:True, Age>=32.5:True] then 0. Coverage:42, accuracy: 0.9761904761904762\n",
      "If [Age>=24.0:False, Sex=male, Pclass>=2:True] then 0. Coverage:115, accuracy: 0.8782608695652174\n",
      "If [Sex=male, Pclass>=2:True, Age>=27.0:False] then 0. Coverage:41, accuracy: 0.8780487804878049\n",
      "If [Age>=28.0:True, Pclass>=2:True, Sex=male] then 0. Coverage:62, accuracy: 0.8064516129032258\n"
     ]
    }
   ],
   "source": [
    "# we can set different accuracy thresholds\n",
    "# we can reorder class labels\n",
    "rules = learn_rules(column_list, data, [1,0], 30, 0.7)\n",
    "for rule in rules[:10]:\n",
    "    print(rule)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Coronavirus symptoms and outcome"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Coronavirus [dataset](https://drive.google.com/file/d/1auN6eSuHtWPXopcD7_bJhkfKYllZCk9Z/view?usp=sharing) (preprocessed as outlined [here](https://github.com/mgbarsky/ml_decision_tree_demo/blob/master/decision_tree_algorithm.ipynb))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = \"../../data_ml_2020/covid_categorical_good.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['sex', 'age', 'diabetes', 'copd', 'asthma', 'imm_supr', 'hypertension',\n",
       "       'cardiovascular', 'obesity', 'renal_chronic', 'tobacco', 'outcome'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(data_file)\n",
    "data = data.dropna(how=\"any\")\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first try with categorical data only - by removing the only numerical column *age*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sex',\n",
       " 'diabetes',\n",
       " 'copd',\n",
       " 'asthma',\n",
       " 'imm_supr',\n",
       " 'hypertension',\n",
       " 'cardiovascular',\n",
       " 'obesity',\n",
       " 'renal_chronic',\n",
       " 'tobacco',\n",
       " 'outcome']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_categorical = data.drop(columns=['age'])\n",
    "column_list = data_categorical.columns.to_numpy().tolist()\n",
    "column_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If [renal_chronic=yes, diabetes=yes, cardiovascular=yes, obesity=no, sex=male, imm_supr=no, hypertension=yes, asthma=no] then dead. Coverage:70, accuracy: 0.6571428571428571\n",
      "If [renal_chronic=yes, diabetes=yes, obesity=no, copd=yes, tobacco=no, hypertension=yes, imm_supr=no, asthma=no, sex=female] then dead. Coverage:31, accuracy: 0.6129032258064516\n"
     ]
    }
   ],
   "source": [
    "# I really want to know what makes covid deadly\n",
    "class_labels = [\"dead\"]\n",
    "rules = learn_rules (column_list, data_categorical, class_labels,30, 0.6)\n",
    "for rule in rules[:20]:\n",
    "    print(rule)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try on both classes and for the entire dataset including age."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sex',\n",
       " 'age',\n",
       " 'diabetes',\n",
       " 'copd',\n",
       " 'asthma',\n",
       " 'imm_supr',\n",
       " 'hypertension',\n",
       " 'cardiovascular',\n",
       " 'obesity',\n",
       " 'renal_chronic',\n",
       " 'tobacco',\n",
       " 'outcome']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_list = data.columns.to_numpy().tolist()\n",
    "column_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If [age>=26:False, tobacco=yes, asthma=yes] then alive. Coverage:47, accuracy: 1.0\n",
      "If [age>=26:False, tobacco=yes, sex=female, obesity=yes] then alive. Coverage:83, accuracy: 1.0\n",
      "If [age>=26:False, tobacco=yes, obesity=no, hypertension=no, sex=female] then alive. Coverage:274, accuracy: 0.9963503649635036\n",
      "If [age>=26:False, hypertension=no, tobacco=yes, obesity=no, renal_chronic=no, imm_supr=no] then alive. Coverage:683, accuracy: 0.9970717423133236\n",
      "If [age>=29:False, hypertension=no, sex=female, tobacco=yes, imm_supr=no] then alive. Coverage:331, accuracy: 1.0\n",
      "If [age>=26:False, asthma=yes, obesity=no, sex=female] then alive. Coverage:246, accuracy: 1.0\n",
      "If [age>=26:False, hypertension=no, sex=female, imm_supr=no, obesity=no, diabetes=no, renal_chronic=no, cardiovascular=no] then alive. Coverage:7773, accuracy: 0.9949826321883443\n",
      "If [age>=30:False, hypertension=no, obesity=no, sex=female, imm_supr=no, tobacco=yes] then alive. Coverage:96, accuracy: 1.0\n",
      "If [age>=30:False, hypertension=no, obesity=no, sex=female, imm_supr=no, diabetes=no, renal_chronic=no, cardiovascular=no, asthma=no] then alive. Coverage:6100, accuracy: 0.9959016393442623\n",
      "If [age>=30:False, sex=male, obesity=no, asthma=yes, renal_chronic=no] then alive. Coverage:413, accuracy: 0.9927360774818402\n",
      "If [age>=30:False, sex=male, obesity=no, tobacco=yes, imm_supr=no, renal_chronic=no, hypertension=no] then alive. Coverage:716, accuracy: 0.9930167597765364\n",
      "If [age>=26:False, sex=male, hypertension=no, obesity=no, diabetes=yes] then alive. Coverage:51, accuracy: 1.0\n",
      "If [age>=29:False, sex=male, hypertension=no, obesity=no, imm_supr=no, cardiovascular=yes] then alive. Coverage:73, accuracy: 1.0\n",
      "If [age>=29:False, sex=male, hypertension=no, obesity=no, imm_supr=no, renal_chronic=no, diabetes=no, copd=no] then alive. Coverage:11718, accuracy: 0.9905273937532002\n",
      "If [age>=34:False, sex=female, asthma=yes, obesity=no, hypertension=no] then alive. Coverage:456, accuracy: 0.9912280701754386\n",
      "If [age>=34:False, sex=female, hypertension=no, tobacco=yes, obesity=no, imm_supr=no] then alive. Coverage:346, accuracy: 0.9971098265895953\n",
      "If [age>=34:False, sex=female, hypertension=no, obesity=no, imm_supr=no, diabetes=no, renal_chronic=no, cardiovascular=no, copd=no] then alive. Coverage:6537, accuracy: 0.9925042068227016\n",
      "If [age>=36:False, hypertension=no, obesity=no, sex=female, imm_supr=no, diabetes=no, asthma=yes] then alive. Coverage:107, accuracy: 1.0\n",
      "If [age>=36:False, hypertension=no, obesity=no, sex=female, imm_supr=no, diabetes=no, tobacco=yes] then alive. Coverage:167, accuracy: 0.9940119760479041\n",
      "If [age>=36:False, hypertension=no, obesity=no, sex=female, imm_supr=no, diabetes=no, renal_chronic=no, cardiovascular=no, copd=no] then alive. Coverage:3162, accuracy: 0.9939911448450348\n"
     ]
    }
   ],
   "source": [
    "# This runs for 12 minutes\n",
    "rules = learn_rules (column_list, data, None, 30, 0.9)\n",
    "for rule in rules[:20]:\n",
    "    print(rule)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Final test. Contact lenses\n",
    "\n",
    "Finally, let's test the algorithm on the original dataset from the PRISM paper - to see what rules does our algorithm produce.\n",
    "\n",
    "The dataset can be downloaded from [here](https://docs.google.com/spreadsheets/d/1z_o28etWJxDdiLV5An_Ni34CZGEWrQGLmngHE79EQmM/edit?usp=sharing). The details of the dataset can be found [here](https://archive.ics.uci.edu/ml/datasets/Lenses)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Attribute Information**:\n",
    "3 Classes:\n",
    "- 1 : the patient should be fitted with hard contact lenses,\n",
    "- 2 : the patient should be fitted with soft contact lenses,\n",
    "- 3 : the patient should not be fitted with contact lenses.\n",
    "\n",
    "Features:\n",
    "1. age of the patient: (1) young, (2) pre-presbyopic, (3) presbyopic\n",
    "2. spectacle prescription:  (1) myope, (2) hypermetrope\n",
    "3. astigmatic:     (1) no, (2) yes\n",
    "4. tear production rate:  (1) reduced, (2) normal\n",
    "\n",
    "Presbyopia is physiological insufficiency of accommodation associated with the aging of the eye that results in progressively worsening ability to focus clearly on close objects. So presbiopic means old.\n",
    "\n",
    "Hypermetropia: far-sightedness, also known as long-sightedness - cannot see close.\n",
    "Myopia: nearsightedness - cannot see at distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = \"../../data_ml_2020/contact_lenses.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'spectacles', 'astigmatism', 'tear production rate',\n",
       "       'lenses type'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(data_file, index_col=['id'])\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace numbers with actual values - for clarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classes\n",
    "conditions = [ data['lenses type'].eq(1), data['lenses type'].eq(2), data['lenses type'].eq(3)]\n",
    "choices = [\"hard\",\"soft\",\"none\"]\n",
    "\n",
    "data['lenses type'] = np.select(conditions, choices)\n",
    "\n",
    "# age groups\n",
    "conditions = [ data['age'].eq(1), data['age'].eq(2), data['age'].eq(3)]\n",
    "choices = [\"young\",\"medium\",\"old\"]\n",
    "\n",
    "data['age'] = np.select(conditions, choices)\n",
    "\n",
    "# spectacles\n",
    "conditions = [ data['spectacles'].eq(1), data['spectacles'].eq(2)]\n",
    "choices = [\"nearsighted\",\"farsighted\"]\n",
    "\n",
    "data['spectacles'] = np.select(conditions, choices)\n",
    "\n",
    "# astigmatism\n",
    "conditions = [ data['astigmatism'].eq(1), data['astigmatism'].eq(2)]\n",
    "choices = [\"no\",\"yes\"]\n",
    "\n",
    "data['astigmatism'] = np.select(conditions, choices)\n",
    "\n",
    "# tear production rate\n",
    "conditions = [ data['tear production rate'].eq(1), data['tear production rate'].eq(2)]\n",
    "choices = [\"reduced\",\"normal\"]\n",
    "\n",
    "data['tear production rate'] = np.select(conditions, choices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['age', 'spectacles', 'astigmatism', 'tear production rate', 'lenses type']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_list = data.columns.to_numpy().tolist()\n",
    "column_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If [tear production rate=reduced] then none. Coverage:12, accuracy: 1.0\n",
      "If [astigmatism=no, spectacles=farsighted] then soft. Coverage:3, accuracy: 1.0\n",
      "If [astigmatism=no, age=young] then soft. Coverage:1, accuracy: 1.0\n",
      "If [astigmatism=no, age=medium] then soft. Coverage:1, accuracy: 1.0\n",
      "If [age=young] then hard. Coverage:2, accuracy: 1.0\n",
      "If [spectacles=nearsighted, astigmatism=yes] then hard. Coverage:2, accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "rules = learn_rules (column_list, data, None, 1, 0.95)\n",
    "for rule in rules[:20]:\n",
    "    print(rule)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright &copy; 2020 Marina Barsky. All rights reserved."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
